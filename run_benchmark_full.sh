#!/bin/bash
# =============================================================================
# OHI Benchmark - Full System Comparison
# =============================================================================
# Complete benchmark comparing all verification systems:
#   - OHI (Open Hallucination Index) - Our hybrid verification system
#   - GPT-4 (OpenAI) - Direct LLM verification baseline
#   - VectorRAG - Vector similarity baseline (public Wikipedia API)
#
# Metrics tested:
#   - Hallucination Detection (HuggingFace datasets)
#   - TruthfulQA (adversarial questions)
#   - FActScore (atomic fact precision)
#   - Latency (response time performance)
#
# NOTE: GPT-4 requires OPENAI_API_KEY with sufficient quota.
#
# Usage: ./run_benchmark_full.sh
# =============================================================================

set -e

CONTAINER="ohi-benchmark"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
OUTPUT_DIR="/app/benchmark_results/full_comparison_${TIMESTAMP}"

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘ OHI Benchmark - Full System Comparison                                 â•‘"
echo "â•‘                                                                        â•‘"
echo "â•‘ Comparing: OHI (2 profiles) vs GPT-4 vs VectorRAG vs GraphRAG           â•‘"
echo "â•‘ Metrics: Hallucination, TruthfulQA, FActScore, Latency (60 samples)     â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Check if container is running
if ! docker ps --format '{{.Names}}' | grep -q "^${CONTAINER}$"; then
    echo "âŒ Container ${CONTAINER} is not running."
    echo "   Start with: docker compose -f docker/compose/docker-compose.yml up -d"
    exit 1
fi

echo "Output directory: ${OUTPUT_DIR}"
echo ""

# Check evaluator availability
echo "Checking evaluator availability..."
docker exec ${CONTAINER} python -c "
from benchmark.comparison_config import ComparisonBenchmarkConfig
config = ComparisonBenchmarkConfig.from_env()

print('  OHI-Latency: âœ“ Ready')
print('  OHI-Max: âœ“ Ready')

if config.openai.is_configured:
    print('  GPT-4: âœ“ API key configured')
else:
    print('  GPT-4: âš  No API key (will be skipped)')

print('  VectorRAG: âœ“ Using Wikipedia API (fair comparison)')
print('  GraphRAG: âœ“ Using Neo4j graph')
"
echo ""

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "Running Full Comparison Benchmark..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

docker exec ${CONTAINER} python -m benchmark.comparison_benchmark \
    --evaluators ohi_latency,ohi_max,graph_rag,vector_rag,gpt4 \
    --metrics hallucination,truthfulqa,factscore,latency \
    --truthfulqa-max 60 \
    --factscore-max 60 \
    --hallucination-max 60 \
    --output-dir "${OUTPUT_DIR}" \
    --chart-dpi 200 \
    --concurrency 5 \
    --verbose

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘ Full Benchmark Complete                                                â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "Results saved to: ./benchmark_results/full_comparison_${TIMESTAMP}"
echo ""
echo "Key output files:"
echo "  ğŸ“Š comparison_dashboard.png   Combined visualization"
echo "  ğŸ“„ *_report.json              Raw benchmark data"
